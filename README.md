# Automatic Hamornic Analysis Based on Non-Chord-Tone-First Approach

## Installation Guide
1. Use `git clone git@github.com:juyaolongpaul/harmonic_analysis.git` in the terminal to clone the project, then use `cd harmonic_analysis` to go into the project folder
2. Create a virtual environment using Python 3. An example is: `virtualenv .env --python=python3.5`. Please change `python3.5` into the one installed in your machine. For example, if your machine has Python 3.6, then use `python3.6`
3. Activate the virtual environment. If you use the command line provided in the second step, you can activate it by `source ./.env/bin/activate` in Mac OS and Linux; in Windows, it is ` .\.env\Scripts\activate`
4. Use `pip install -r requirements_gpu.txt` to install the required packages if you have a CUDA-compatiable GPU and you want to train the networks on GPU; use `pip install -r requirements_cpu.txt` if you want to train the networks on CPU
5. Use `python main.py` to run the project
## Workflow Overview
In `main.py`, there are many parameters to customize regarding the analytical styles, types of machine learning models, model architectures, and hyper-parameters. I will provide a chart introducing all the available combinations of these parameters below.

For now, the project can accept Bach and Praetorius chorales and the corresponding annotations from [here](https://natsguitar.github.io/FlexibleChoraleHarmonicAnalysisGUI/) based on my co-authored paper with Nathaniel Condit-Schultz called ["A Flexible Approach to Automated Harmonic Analysis: Multiple Annotations of Chorales by Bach and Praetorius"](http://ismir2018.ircam.fr/doc/pdfs/283_Paper.pdf), where the music and annotations are encoded in `.krn` files. Afterward, a series of functions are applied to pre-process the data to feed the machine learning models as inputs and outputs for learning, and then the model will predict non-chord tones and the corresponding chord labels on the test set, presented as musicXML files for users to see the end results. Specifically:
* `extract_chord_labels` function is used to extract the chord labels from the `.krn` files and save them as `.txt` files. For example, for the maximally melodic style (since this Github repository already provide the annotations in this style), the `.krn` files are located under `./genos-corpus/answer-sheets/bach-chorales/New_annotation/rule_MaxMel/`, and the generated `.txt` files (for chord labels) are saved in the same directory. 
* `annotation_translation` function is used to translate the chord syntax into one recognizable by `music21`, a package which this project will rely on in order to do various music processing. 
* `provide_path_12keys` will transpose the chord annotations into 12 possible keys, so we can use either the annotations in the key of C (without data augmentation) to train the model, or use the annotations in all keys (with data augmentation) to train the model. Correspondingly, `transpose_polyphony` is used to translate the music into 12 keys as well. These files will all be saved in the directory of `./genos-corpus/answer-sheets/bach-chorales/New_annotation/rule_MaxMel/`, for example. 
* Once we have the music and the chord labels ready, `generate_data_windowing_non_chord_tone_new_annotation_12keys` will translate all of them into a (one-hot) encoding which can be directly used by the machine learning models. These files will be saved in the directory of `./data_for_ML`.
* Last, `train_and_predict_non_chord_tone` will train the machine learning model, saves all the models, output all the performance information into the text file (models and performance infomation are saved in the directory of `./ML_result/`), and visualize all the predicted non-chord-tones as well as the chord labels through generated musicXML files (saved in the directory of `/predicted_result`).   
