---
layout: default
title: The Aim of This Project 

---

## The Aim of This Project

### Introduction

Despite being a core component of Western music theory, Harmonic analysis is difficult because: (1) It is a time-consuming process requiring years of training. (2) Even expert analysts will often disagree in their interpretations of certain passages, and are often inconsistent in their interpretive styles. Due to these difficulties, harmonic analysis remains a subjective endeavor, resistant to automation. As a result, few large datasets of high-quality harmonic analysis data exist, a situation that has significantly retarded the systematic study ofWestern harmony.

In this project, I propose an innovative workflow to conduct harmonic analysis automatically with multiple analytical styles using artificial intelligence. This approach will be the first of its kind to explicitly address and systematically resolve the ambiguities and interpretive flexibility of harmonic analysis. Hence, the vast amounts of generated harmonic analyses can be curated into a searchable, large-scale database, serving as an invaluable resource for music theoretic, musicological, and music information retrieval research.

The project contains four steps. First, I will define two distinct harmonic analysis rubrics – maximally melodic and maximally harmonic – with a definitive set of rules. Second, instead of requiring annotators to follow the rules and label the whole dataset from scratch, I will develop a rule-based algorithm to generate preliminary harmonic analyses. Although the algorithm cannot deal with sophisticated passages as well as annotators, it can generate 100% consistent analyses in each style. Third, annotators will modify a subset of the analyses. To make the modification consistent, multiple annotators will work on the same passage, and modify analyses based on consensus. Last, these highly consistent and accurate analyses will be used to train computers to generate analyses automatically, in which computers (machine learning models) learn just as music students learn from textbooks written by expert analysts. 

In this way, not only are we able to minimize the work of the annotators with artificial intelligence techniques (issue 1 addressed), and create consistent, accurate harmonic analysis with multiple interpretive styles (issue 2 addressed), also we will have machine learning models to generate harmonic analyses automatically for the unannotated music.

### Motivation for This Repository 

This repository specifically deals with the last step of the proposal. The first two steps of the proposal have been addressed in the [paper](http://ismir2018.ircam.fr/doc/pdfs/283_Paper.pdf) on two largely homorhythmic datasets: chorales by Praetorius (1571-1621) and Bach. Currently, this repository utilizes the annotations introduced in the paper to train machine learning models to conduct harmonic analysis automatically. In the future, we will address the step three of the proposal by hiring expert annotators to modify the preliminary analyses generated by the rule-based algorithm. Once the highly consistent and accurate analyses are obtained, the machine learning models are expected to generate the highly consistent and accurate analyses of the similar quality for the un-annotated music.

Specifically, I proposed a NCT identification [model](https://dl.acm.org/citation.cfm?id=3144753), which is considered as an essential step for harmonic analysis in the literature. Once the model identifies and removes NHTs from the music, a dictionary is defined to map harmonic tones into chords. The traditional workflow of harmonic analysis, compared to the proposed "non-chord-tone-first" appraoch, is illustrated in the figure below on the left and right side, respectively. 

![image](https://user-images.githubusercontent.com/9313094/50776583-5942eb00-1267-11e9-8362-95442d735ae7.png)

### Overview of the Chord Inferring Algorithm
Although mapping chord tones into chord labels sounds like a trivial job, it can be quite complicated since the chord tones in many slices will not comprise a chord, and thus have to refer to adjacent slices to determine the final chord label. Therefore, I wrote a rule-based algorithm for this purpose. The pseudo-code of this algorithm can be divided into the following steps:
* All the slices will be scanned first, and for all the slices whose the chord tones comprise a chord label, the label will be the annotation for the slice; otherwise, the slice will be labeled as "Undetermined".
* All the "Undetermined" slices will be scanned for the second time. For each slice, I will find the closest preceding and following slices that have chord labels. To determine which chord label will be chosen for the "Undetermined" slice:
    * First, which chord label that overlaps the most chord tones in the "Undetermined" slice will be chosen as the chord label.
    * If the numbers of the overlapping chord tones are the same, choose the chord label whose root is the bass of the slice (prefer the chord in the root position); else, choose the preceding slice's chord label as the one for the "Undertermined" slice.
    * For all the slices containing two chord tones, and they are (1) minor third (2) major third (3) perfect fifth (4) tritone apart:
        * Try to replace them with a chord label from the adjacent slices, using the same scheme from the last step **only if** the chord label contains both chord tones, otherwise:
            * Minor third becomes a minor triad where the fifth is supplemented.
            * Major third becomes a major triad where the fifth is supplemented.
            * Perfect fifth becomes a major triad where the third is supplemented.
            * Tritone becomes a diminished triad where the third is supplemented. 
    * It seems like the algorithm still has room to improve. I ran the algorithm on the ground truth NCTs, and got an accuracy of 96%. I will look into the 4% errors and improve the algorithm accordingly.
        * I looked into the 4% errors, and about 2/3 of the errors are because the original annotations are problematic. For example, chorale 018 measure 12:
            ![image](https://user-images.githubusercontent.com/9313094/51352277-2543a300-1a7b-11e9-92c3-896da3f84950.png)
            
            Since most of the chord tones for`c` do not exist in the sonorities (the annotations and the sonorities hardly match), so it is impossible for the chord inferring algorithm to know these missing chord tones and predict the chord label which matches the ground truth. As a result, the predicted chord labels are "errors", but the real errors are the annotations.
        * For the rest 1/3 errors, correcting them by updating the algorithm will usually lead to other errors. For example, chorale 023 measure 11:
            ![image](https://user-images.githubusercontent.com/9313094/51352977-38577280-1a7d-11e9-8438-5d99362763cb.png)
            
            For these two slices, the chord tones are a major third apart, since they can be contained by `am` chord, the algorithm consider the chord as `am`, not `c`, which causes errors. However, if I fix the errors (so the major/minor third will ALWAYS become a major/minor triad), the slice on measure 9, second half of the third beat will be wrong, since the chord tones are `EG`, and it can make up a `em` chord.
        * Also notice that, the annotations are generated in the style of maximally melodic, and when the style changes, the annotations might change drastically. Therefore, I want to develop a general algorithm that can work equally well (or badly...) for each style.
        * Alternatively, we might want to consider a machine learning chord inferring model, which can offer more flexibilities to cater for each analytical style. However, it is uncertain that the machine learning model will beat the performance of the rule-based one. I will try it at some point, although this is not the top priority now. 
        
